{
  "cards": [
    {
      "id": 101,
      "concept": "Why does feature representation dominate algorithm choice in predictive modeling?",
      "explanation": "Feature representation dominates because predictive performance depends primarily on whether predictors encode the true underlying signal. No algorithm can recover signal that is absent from the feature space. The quality of feature engineering determines the upper bound of model performance, while algorithm choice only affects how close we get to that bound.",
      "topics": ["Feature Engineering", "Predictive Modeling"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/a-simple-example.html"
    },
    {
      "id": 102,
      "concept": "What is data leakage and why is it dangerous in feature engineering?",
      "explanation": "Data leakage occurs when information unavailable at prediction time is used during model training or feature engineering. This produces unrealistically optimistic performance that fails in real deployment. In feature engineering, leakage can occur through improper preprocessing (e.g., using test set statistics), temporal leakage (using future information), or target leakage (including variables that directly encode the outcome).",
      "topics": ["Feature Engineering", "Data Leakage"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/important-concepts.html"
    },
    {
      "id": 103,
      "concept": "Explain the relationship between model bias and variance in the context of feature engineering.",
      "explanation": "Model bias reflects the inability to capture the true relationship, while variance reflects sensitivity to training data. Feature engineering can reduce bias by creating features that better represent the underlying signal (e.g., interactions, transformations). However, excessive feature engineering can increase variance by allowing models to overfit to noise. The bias-variance trade-off must be managed through proper resampling and validation during feature creation.",
      "topics": ["Feature Engineering", "Model Bias", "Variance"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/important-concepts.html#model-bias-and-variance"
    },
    {
      "id": 104,
      "concept": "What is the difference between experience-driven and empirically-driven modeling approaches?",
      "explanation": "Experience-driven modeling uses domain knowledge and expert understanding to guide feature creation and selection. Empirically-driven modeling relies on data-driven methods to discover features automatically. The best approach combines both: using domain knowledge to create candidate features and empirical methods to validate and select among them. Pure empirical approaches risk missing important domain-specific relationships, while pure experience-driven approaches may miss unexpected patterns in the data.",
      "topics": ["Feature Engineering", "Modeling Approaches"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/important-concepts.html#experience-driven-modeling-and-empirically-driven-modeling"
    },
    {
      "id": 201,
      "concept": "Why is proper data splitting critical before any preprocessing or feature engineering?",
      "explanation": "Data must be split into training and testing sets before preprocessing to prevent data leakage. If statistics from the test set (means, standard deviations, encodings) are used to transform training data, the model has seen information from the test set. This creates optimistic bias in performance estimates. All preprocessing steps, including feature engineering, must be fit only on training data and then applied to test data.",
      "topics": ["Data Splitting", "Preprocessing"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/splitting.html"
    },
    {
      "id": 202,
      "concept": "What are the key considerations when preprocessing data for predictive modeling?",
      "explanation": "Key considerations include: (1) Ensuring preprocessing is fit only on training data to prevent leakage, (2) Handling missing values appropriately (deletion, encoding, imputation), (3) Scaling/normalizing numeric predictors when needed, (4) Encoding categorical predictors appropriately, (5) Detecting and handling outliers, (6) Ensuring preprocessing steps are reproducible and can be applied to new data. All preprocessing must be part of the modeling pipeline evaluated through resampling.",
      "topics": ["Preprocessing", "Predictive Modeling"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/preprocessing.html"
    },
    {
      "id": 203,
      "concept": "How should exploratory analysis inform feature engineering decisions?",
      "explanation": "Exploratory analysis reveals structure, relationships, anomalies, and data quality issues that directly inform feature engineering. It helps identify: (1) Non-linear relationships requiring transformations, (2) Interactions between predictors, (3) Missing data patterns, (4) Outliers and their nature, (5) Distributions suggesting appropriate transformations, (6) Correlations indicating redundancy or potential feature combinations. However, exploration must be done carefully to avoid overfitting to patterns that may not generalize.",
      "topics": ["Exploratory Analysis", "Feature Engineering"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/exploration.html"
    },
    {
      "id": 301,
      "concept": "What are the different types of resampling methods and when should each be used?",
      "explanation": "Main types include: (1) V-fold cross-validation: standard for most cases, provides good bias-variance trade-off, (2) Monte Carlo cross-validation: useful when data order matters or for time series, (3) Bootstrap: good for small datasets, provides confidence intervals, (4) Rolling origin forecasting: essential for time series with temporal dependencies, (5) Validation sets: used for final model selection after tuning. Choice depends on data size, structure, and whether temporal/spatial dependencies exist.",
      "topics": ["Resampling", "Cross-Validation"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/a-review-of-the-predictive-modeling-process.html#resampling"
    },
    {
      "id": 302,
      "concept": "What should be included inside the resampling loop versus outside?",
      "explanation": "Inside resampling (within each fold): feature engineering, preprocessing, feature selection, model training, and hyperparameter tuning. Outside resampling: final model training on full training set after selecting optimal approach. This ensures that performance estimates reflect the entire modeling process, including feature engineering, preventing overfitting. Only the final selected model is trained on all training data for deployment.",
      "topics": ["Resampling", "Feature Engineering"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/a-review-of-the-predictive-modeling-process.html#what-should-be-included-inside-of-resampling"
    },
    {
      "id": 303,
      "concept": "How do regression and classification metrics differ, and why is context important in metric selection?",
      "explanation": "Regression metrics (RMSE, MAE, RÂ²) measure continuous prediction errors. Classification metrics (accuracy, sensitivity, specificity, AUC) measure categorical prediction performance. Context matters because: (1) Business costs may favor certain errors (e.g., false negatives in medical diagnosis), (2) Class imbalance requires metrics like precision-recall, (3) Ranking problems need AUC or lift, (4) Some metrics are insensitive to class imbalance (AUC) while others aren't (accuracy). The metric should reflect the actual cost/benefit of prediction errors in the application domain.",
      "topics": ["Model Evaluation", "Metrics"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/a-review-of-the-predictive-modeling-process.html#measuring-performance"
    },
    {
      "id": 304,
      "concept": "What is the relationship between tuning parameters and overfitting in feature engineering?",
      "explanation": "Tuning parameters control model complexity. When feature engineering creates many features or complex transformations, models have more capacity to overfit. Proper tuning (via resampling) finds the right balance: enough complexity to capture signal but not so much that it memorizes noise. Feature engineering and tuning are interdependent - better features may require different tuning, and tuning can reveal which engineered features are actually useful versus overfitting.",
      "topics": ["Model Tuning", "Overfitting"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/a-review-of-the-predictive-modeling-process.html#tuning-parameters-and-overfitting"
    },
    {
      "id": 401,
      "concept": "How do different visualization types help identify feature engineering opportunities?",
      "explanation": "Different visualizations reveal different patterns: (1) Box plots/violin plots show distributions and outliers suggesting transformations, (2) Scatter plots reveal non-linear relationships requiring basis expansions, (3) Heatmaps show correlations suggesting redundancy or potential interactions, (4) Line plots reveal temporal patterns requiring time-based features, (5) PCA plots show dimensionality and potential for feature reduction. Each visualization type targets specific feature engineering needs.",
      "topics": ["Visualization", "Feature Engineering"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/exploratory-visualizations.html"
    },
    {
      "id": 402,
      "concept": "What is the role of post-modeling visualizations in feature engineering?",
      "explanation": "Post-modeling visualizations help evaluate feature engineering effectiveness by: (1) Showing residual patterns that indicate missing features or transformations, (2) Revealing which engineered features contribute most to predictions, (3) Identifying regions where the model performs poorly (suggesting missing interactions), (4) Comparing feature importance across models, (5) Detecting systematic errors that suggest additional feature engineering is needed. They guide iterative improvement of feature sets.",
      "topics": ["Visualization", "Model Evaluation"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/exploratory-visualizations.html#post-modeling-exploratory-visualizations"
    },
    {
      "id": 403,
      "concept": "How can faceting, colors, and shapes enhance exploratory visualizations for feature engineering?",
      "explanation": "Faceting splits data by categorical variables to reveal conditional relationships that suggest interactions. Colors can encode additional variables to discover multivariate patterns and interactions. Shapes distinguish groups to identify differential relationships. These augmentations help identify: (1) Interactions between predictors (different slopes across facets), (2) Conditional effects (patterns that differ by color/shape), (3) Missing feature combinations that would improve predictions. They transform simple plots into powerful feature discovery tools.",
      "topics": ["Visualization", "Feature Discovery"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/exploratory-visualizations.html#augmenting-visualizations-through-faceting-colors-and-shapes"
    },
    {
      "id": 501,
      "concept": "What are the different approaches for encoding categorical predictors with many categories?",
      "explanation": "Approaches include: (1) Dummy variables with regularization to handle high cardinality, (2) Supervised encoding (target encoding, likelihood encoding) that uses outcome information, (3) Frequency-based encoding (count, proportion), (4) Hash encoding for extremely high cardinality, (5) Grouping rare categories together. The choice depends on cardinality, sample size, and whether the encoding can be learned within resampling to prevent leakage. Supervised encodings must be carefully validated to avoid overfitting.",
      "topics": ["Categorical Encoding", "Feature Engineering"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/encoding-categorical-predictors.html#encoding-predictors-with-many-categories"
    },
    {
      "id": 502,
      "concept": "How should novel categories (unseen in training) be handled during encoding?",
      "explanation": "Novel categories require special handling: (1) Create a 'missing' or 'other' category during training, (2) Use encodings that generalize (e.g., frequency-based rather than target encoding), (3) For supervised encodings, fall back to a default value (e.g., overall mean for target encoding), (4) Consider grouping rare categories during training to create a catch-all category. The strategy must be defined during training and consistently applied to test data. This prevents data leakage and ensures the model can handle new categories.",
      "topics": ["Categorical Encoding", "Data Leakage"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/encoding-categorical-predictors.html#approaches-for-novel-categories"
    },
    {
      "id": 503,
      "concept": "What is supervised encoding and what are its risks and benefits?",
      "explanation": "Supervised encoding uses outcome information to create numeric encodings (e.g., target encoding, likelihood encoding). Benefits: captures predictive signal, reduces dimensionality, can improve model performance. Risks: (1) Data leakage if not done within resampling, (2) Overfitting to training data, especially with small category sizes, (3) Requires careful validation. Must be computed separately for each resampling fold using only training data. Smoothing or regularization helps prevent overfitting to rare categories.",
      "topics": ["Supervised Encoding", "Data Leakage"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/encoding-categorical-predictors.html#supervised-encoding-methods"
    },
    {
      "id": 504,
      "concept": "When should factors be used versus dummy variables in tree-based models?",
      "explanation": "Tree-based models can handle factors directly, which is more efficient than dummy variables. However, factors with many levels can cause: (1) Computational inefficiency, (2) Overfitting to rare categories, (3) Poor splits. Dummy variables with regularization (e.g., lasso) can handle high cardinality better. For tree models, consider: (1) Using factors for low cardinality (<10 levels), (2) Encoding high cardinality categories before tree modeling, (3) Using supervised encodings that preserve signal while reducing cardinality. The choice depends on cardinality and sample size.",
      "topics": ["Categorical Encoding", "Tree Models"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/encoding-categorical-predictors.html#factors-versus-dummy-variables-in-tree-based-models"
    },
    {
      "id": 601,
      "concept": "What are 1:1 transformations and when are they useful?",
      "explanation": "1:1 transformations apply a function to a single predictor (e.g., log, square root, Box-Cox). They are useful when: (1) Data is skewed and needs normalization, (2) Relationships are non-linear but monotonic, (3) Variance is non-constant (heteroscedasticity), (4) Data has specific distributions requiring transformation. Examples: log for multiplicative relationships, square root for count data, inverse for rates. They preserve the one-to-one mapping while making relationships more linear and variance more constant.",
      "topics": ["Numeric Transformations", "Feature Engineering"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/engineering-numeric-predictors.html#one-to-one-transformations"
    },
    {
      "id": 602,
      "concept": "What are basis expansions and splines, and when should they be used?",
      "explanation": "Basis expansions create multiple features from one predictor using basis functions (e.g., polynomial, Fourier, spline). Splines use piecewise polynomials with smooth connections. They are useful when: (1) Relationships are non-linear and non-monotonic, (2) The functional form is unknown, (3) Flexibility is needed without overfitting. Splines provide smooth, flexible curves. However, they increase dimensionality (1:many transformation) and require regularization or careful tuning to prevent overfitting. Must be validated through resampling.",
      "topics": ["Basis Expansions", "Splines"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/engineering-numeric-predictors.html#nonlinear-features-via-basis-expansions-and-splines"
    },
    {
      "id": 603,
      "concept": "What are linear projection methods and how do they create features?",
      "explanation": "Linear projection methods (PCA, ICA, factor analysis) create new features as linear combinations of original predictors. They reduce dimensionality while preserving variance (PCA) or independence (ICA). Benefits: (1) Dimensionality reduction, (2) Noise reduction, (3) Decorrelation. Limitations: (1) Linear combinations may not capture non-linear relationships, (2) Interpretability is lost, (3) Must be fit on training data only. Useful when: high dimensionality, multicollinearity, or when interpretability of individual features is less important than predictive performance.",
      "topics": ["Dimensionality Reduction", "PCA"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/engineering-numeric-predictors.html#linear-projection-methods"
    },
    {
      "id": 604,
      "concept": "When should discretization be used as a feature engineering technique?",
      "explanation": "Discretization (binning) should be used as a last resort when: (1) Non-linear relationships are too complex for simple transformations, (2) Models cannot handle continuous variables well, (3) Interpretability requires categorical features. However, it loses information and can reduce predictive power. Better alternatives include splines, basis expansions, or tree-based models that handle non-linearities naturally. If discretization is used, bin boundaries must be determined from training data only and validated through resampling.",
      "topics": ["Discretization", "Feature Engineering"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/engineering-numeric-predictors.html#discretize-predictors-as-a-last-resort"
    },
    {
      "id": 701,
      "concept": "What are the guiding principles in searching for interaction effects?",
      "explanation": "Principles include: (1) Start with domain knowledge to identify plausible interactions, (2) Use visualization to detect potential interactions, (3) Consider interactions between predictors that are individually predictive, (4) Be aware that the number of possible interactions grows combinatorially, (5) Validate interactions through resampling to avoid overfitting, (6) Consider whether interactions are truly necessary or if non-linear models can capture them automatically. The search must balance thoroughness with computational feasibility and overfitting risk.",
      "topics": ["Interactions", "Feature Engineering"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/detecting-interaction-effects.html#guiding-principles-in-the-search-for-interactions"
    },
    {
      "id": 702,
      "concept": "How does penalized regression help identify predictive interactions?",
      "explanation": "Penalized regression (lasso, elastic net) can identify interactions by: (1) Including all pairwise interactions as features, (2) Using regularization to select which interactions are predictive, (3) Shrinking coefficients of non-predictive interactions to zero. This works when the number of interactions is manageable. However, with p predictors, there are p(p-1)/2 pairwise interactions, which can be computationally expensive. Group lasso or hierarchical interactions can help. Must be validated through resampling to ensure selected interactions generalize.",
      "topics": ["Interactions", "Penalized Regression"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/detecting-interaction-effects.html#penalized-regression"
    },
    {
      "id": 703,
      "concept": "How can tree-based methods help identify interactions when complete enumeration is impossible?",
      "explanation": "Tree-based methods naturally capture interactions through their splitting structure. A split on variable A followed by a split on variable B creates an implicit interaction. Methods include: (1) Examining tree structures to identify important interaction patterns, (2) Using tree-based feature importance to guide interaction creation, (3) Creating interactions based on variables that frequently split together, (4) Using random forests or gradient boosting to discover complex interactions automatically. This is more scalable than enumerating all interactions but requires careful interpretation.",
      "topics": ["Interactions", "Tree Models"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/detecting-interaction-effects.html#tree-based-methods"
    },
    {
      "id": 801,
      "concept": "What are the different strategies for handling missing data in feature engineering?",
      "explanation": "Strategies include: (1) Deletion: remove cases or variables with missingness (acceptable if missingness is random and small), (2) Encoding missingness: create indicator variables for missing patterns, (3) Imputation: fill missing values (mean, median, mode, model-based, k-nearest neighbors), (4) Models resistant to missingness: tree-based models that handle missingness natively. The choice depends on: missingness mechanism (MCAR, MAR, MNAR), proportion missing, and whether missingness itself is informative. All strategies must be applied within resampling to prevent leakage.",
      "topics": ["Missing Data", "Imputation"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/handling-missing-data.html"
    },
    {
      "id": 802,
      "concept": "When is missingness itself informative and how should it be encoded?",
      "explanation": "Missingness is informative when the fact that data is missing correlates with the outcome (e.g., patients who don't complete surveys may have different outcomes). This should be encoded by: (1) Creating indicator variables for missing patterns, (2) Using separate imputation strategies for different missing patterns, (3) Treating missingness as a feature itself. The missingness indicator can be highly predictive. This is particularly important when missingness is not random (MNAR - Missing Not At Random) and the pattern of missingness contains signal about the outcome.",
      "topics": ["Missing Data", "Feature Engineering"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/handling-missing-data.html#encoding-missingness"
    },
    {
      "id": 803,
      "concept": "What are the trade-offs between different imputation methods?",
      "explanation": "Simple imputation (mean/median/mode): fast, but ignores relationships and can bias variance estimates. Model-based imputation: captures relationships but can overfit and requires careful validation. K-nearest neighbors: uses local patterns but computationally expensive. Multiple imputation: accounts for uncertainty but complex to implement in predictive modeling. The choice depends on: (1) Amount of missing data, (2) Whether relationships between variables can inform imputation, (3) Computational constraints, (4) Whether imputation must be done within resampling. All imputation must be fit on training data only.",
      "topics": ["Imputation", "Missing Data"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/handling-missing-data.html#imputation-methods"
    },
    {
      "id": 901,
      "concept": "What is the difference between experimental unit and unit of prediction in profile data?",
      "explanation": "Experimental unit is the entity on which measurements are taken (e.g., a manufacturing batch, a patient visit). Unit of prediction is what we want to predict (e.g., final product quality, patient outcome). They may differ: we might measure multiple times per experimental unit but predict at the unit level. Understanding this distinction is critical for: (1) Proper feature engineering (aggregating measurements correctly), (2) Avoiding data leakage (not using future information), (3) Ensuring predictions are at the correct granularity. Misalignment causes invalid models.",
      "topics": ["Profile Data", "Experimental Design"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/working-with-profile-data.html#what-are-the-experimental-unit-and-the-unit-of-prediction"
    },
    {
      "id": 902,
      "concept": "How can background noise be reduced in profile data feature engineering?",
      "explanation": "Background reduction techniques include: (1) Baseline correction: subtract baseline measurements, (2) Smoothing: remove high-frequency noise (moving averages, splines), (3) Normalization: scale profiles to remove systematic variations, (4) Alignment: correct for shifts in measurement (e.g., time alignment), (5) Filtering: remove known artifacts or noise patterns. The goal is to preserve signal while removing noise that doesn't contribute to prediction. However, aggressive noise reduction can remove signal, so validation through resampling is essential.",
      "topics": ["Profile Data", "Signal Processing"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/working-with-profile-data.html#reducing-background"
    },
    {
      "id": 903,
      "concept": "How can correlation in profile data be exploited for feature engineering?",
      "explanation": "Profile data often has high correlation (e.g., adjacent time points, nearby sensors). This can be exploited by: (1) Using dimensionality reduction (PCA) to capture correlated patterns, (2) Creating summary statistics that aggregate correlated measurements, (3) Using the correlation structure to inform feature selection, (4) Creating features that capture patterns across correlated variables (e.g., trends, changes). However, correlation can also indicate redundancy, so feature selection may be needed. The correlation structure itself can be informative (e.g., correlation matrices as features).",
      "topics": ["Profile Data", "Correlation"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/working-with-profile-data.html#exploiting-correlation"
    },
    {
      "id": 1001,
      "concept": "What are the main goals of feature selection?",
      "explanation": "Goals include: (1) Reducing noise by removing irrelevant features, (2) Improving generalization by preventing overfitting, (3) Enhancing interpretability by focusing on important predictors, (4) Reducing computational cost, (5) Improving model stability. Feature selection helps when: there are many features relative to samples, features are noisy or redundant, or interpretability is important. However, feature selection itself can overfit if not done carefully through resampling.",
      "topics": ["Feature Selection"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/feature-selection-overview.html#goals-of-feature-selection"
    },
    {
      "id": 1002,
      "concept": "What are the different classes of feature selection methodologies?",
      "explanation": "Main classes: (1) Filter methods: select features based on univariate statistics (correlation, mutual information) independent of the model, (2) Wrapper methods: use model performance to guide selection (forward/backward selection, recursive feature elimination), (3) Embedded methods: selection is built into model training (lasso, tree-based importance). Filters are fast but ignore feature interactions. Wrappers consider interactions but are computationally expensive. Embedded methods balance both but are model-specific. All must be validated through resampling.",
      "topics": ["Feature Selection", "Methodology"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/feature-selection-overview.html#classes-of-feature-selection-methodologies"
    },
    {
      "id": 1003,
      "concept": "How do irrelevant features affect model performance and why does feature selection help?",
      "explanation": "Irrelevant features: (1) Add noise that models try to fit, increasing variance, (2) Dilute signal by increasing search space, (3) Increase risk of overfitting, especially with many features relative to samples, (4) Can create spurious correlations that don't generalize. Feature selection helps by: (1) Reducing dimensionality and noise, (2) Focusing models on signal-bearing features, (3) Improving generalization, (4) Reducing computational cost. However, aggressive selection can remove relevant features, so validation is critical. The curse of dimensionality makes feature selection especially important in high-dimensional settings.",
      "topics": ["Feature Selection", "Overfitting"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/feature-selection-overview.html#effect-of-irrelevant-features"
    },
    {
      "id": 1004,
      "concept": "Why is external validation critical when evaluating feature selection methods?",
      "explanation": "External validation (on a held-out test set) is critical because: (1) Feature selection can overfit to training data, finding spurious patterns, (2) Performance estimates from resampling may be optimistic if feature selection isn't properly nested, (3) The selected feature set may not generalize to new data, (4) Multiple comparisons across many feature subsets increase false discovery. External validation provides unbiased estimate of true performance. Feature selection must be done within each resampling fold, and final evaluation on a completely independent test set.",
      "topics": ["Feature Selection", "Validation"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/feature-selection-overview.html#overfitting-to-predictors-and-external-validation"
    },
    {
      "id": 1101,
      "concept": "What are simple filters and when are they appropriate for feature selection?",
      "explanation": "Simple filters use univariate statistics (correlation, mutual information, chi-square) to rank features independently. They are appropriate when: (1) Features are relatively independent, (2) Computational efficiency is important, (3) As a screening step before more sophisticated methods, (4) When interpretability requires understanding individual feature contributions. Limitations: (1) Ignore feature interactions, (2) May miss features that are only predictive in combination, (3) Can select redundant features. They work best as a first pass to reduce dimensionality before wrapper or embedded methods.",
      "topics": ["Feature Selection", "Filter Methods"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/greedy-search-methods.html#simple-filters"
    },
    {
      "id": 1102,
      "concept": "How does Recursive Feature Elimination (RFE) work and what are its advantages?",
      "explanation": "RFE is a wrapper method that: (1) Trains a model on all features, (2) Ranks features by importance, (3) Removes the least important, (4) Repeats until desired number of features. Advantages: (1) Considers feature interactions through model training, (2) Can use any model with feature importance, (3) Finds feature subsets that work well together. Disadvantages: (1) Computationally expensive (trains many models), (2) Greedy (may miss optimal subsets), (3) Must be done within resampling to prevent overfitting. The number of features to retain must be tuned.",
      "topics": ["Feature Selection", "RFE"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/greedy-search-methods.html#recursive-feature-elimination"
    },
    {
      "id": 1103,
      "concept": "What are the differences between forward and backward stepwise selection?",
      "explanation": "Forward selection: starts with no features, adds one at a time based on improvement. Backward elimination: starts with all features, removes one at a time. Forward is faster when few features are needed, backward when most features are needed. Both are greedy (don't guarantee optimal subset) and can get stuck in local optima. Both must be validated through resampling. Forward can miss features that are only useful together. Backward can be computationally expensive with many features. Hybrid approaches (bidirectional) can help but are more complex.",
      "topics": ["Feature Selection", "Stepwise Selection"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/greedy-search-methods.html#stepwise-selection"
    },
    {
      "id": 1201,
      "concept": "How does Simulated Annealing work for feature selection and what are its advantages over greedy methods?",
      "explanation": "Simulated Annealing is a global search method that: (1) Starts with a random feature subset, (2) Proposes changes (add/remove features), (3) Accepts improvements, (4) Accepts worse solutions probabilistically (decreasing over time), (5) Escapes local optima. Advantages over greedy: (1) Can escape local optima, (2) Explores more of the feature space, (3) Can find better feature subsets. Disadvantages: (1) More computationally expensive, (2) Requires tuning of temperature schedule, (3) Still not guaranteed to find global optimum. Must be validated through resampling to prevent overfitting.",
      "topics": ["Feature Selection", "Simulated Annealing"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/global-search-methods.html#simulated-annealing"
    },
    {
      "id": 1202,
      "concept": "How do Genetic Algorithms work for feature selection and when are they most useful?",
      "explanation": "Genetic Algorithms: (1) Maintain a population of feature subsets, (2) Evaluate fitness (model performance), (3) Select parents based on fitness, (4) Create offspring through crossover and mutation, (5) Evolve over generations. Most useful when: (1) Feature space is very large, (2) Interactions are important, (3) Greedy methods get stuck, (4) Computational resources allow. They can discover complex feature interactions and escape local optima. However, they require: careful tuning of parameters (population size, mutation rate), many model evaluations, and validation through resampling to prevent overfitting.",
      "topics": ["Feature Selection", "Genetic Algorithms"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "hard",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/global-search-methods.html#genetic-algorithms"
    },
    {
      "id": 1203,
      "concept": "How can sparsity be coerced in feature selection methods?",
      "explanation": "Sparsity (selecting few features) can be coerced by: (1) Using regularization (lasso, elastic net) that penalizes the number of features, (2) Setting explicit limits on feature count in search methods, (3) Using penalties that favor smaller feature sets, (4) Post-processing to remove redundant features. Sparsity is desirable for: interpretability, reducing overfitting, and computational efficiency. However, forcing too much sparsity can remove important features. The optimal sparsity level must be determined through resampling and validation, balancing performance with interpretability.",
      "topics": ["Feature Selection", "Sparsity"],
      "origin": "Feature Engineering and Selection - Max Kuhn",
      "difficulty": "medium",
      "createdAt": "2024-01-15T10:30:00Z",
      "lastReviewed": null,
      "nextReview": null,
      "repetitions": 0,
      "correctCount": 0,
      "incorrectCount": 0,
      "history": [],
      "status": "pending",
      "reference": "https://bookdown.org/max/FES/global-search-methods.html#coercing-sparsity"
    }
  ],
  "topics": [
    "Feature Engineering",
    "Predictive Modeling",
    "Data Leakage",
    "Model Bias",
    "Variance",
    "Modeling Approaches",
    "Data Splitting",
    "Preprocessing",
    "Exploratory Analysis",
    "Resampling",
    "Cross-Validation",
    "Model Evaluation",
    "Metrics",
    "Model Tuning",
    "Overfitting",
    "Visualization",
    "Feature Discovery",
    "Categorical Encoding",
    "Numeric Transformations",
    "Basis Expansions",
    "Splines",
    "Dimensionality Reduction",
    "PCA",
    "Discretization",
    "Interactions",
    "Penalized Regression",
    "Tree Models",
    "Missing Data",
    "Imputation",
    "Profile Data",
    "Experimental Design",
    "Signal Processing",
    "Correlation",
    "Feature Selection",
    "Methodology",
    "Validation",
    "Filter Methods",
    "RFE",
    "Stepwise Selection",
    "Simulated Annealing",
    "Genetic Algorithms",
    "Sparsity"
  ],
  "origins": [
    "Feature Engineering and Selection - Max Kuhn"
  ],
  "metadata": {
    "totalCards": 36,
    "lastUpdated": "2024-01-15",
    "version": "1.0",
    "book": "Feature Engineering and Selection: A Practical Approach for Predictive Models",
    "authors": "Max Kuhn and Kjell Johnson",
    "bookUrl": "https://bookdown.org/max/FES/"
  }
}

